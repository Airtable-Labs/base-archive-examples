{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for Table: Movies\n",
      "Checking Azure for existing CSV\n",
      "Existing file found, uploading new version\n",
      "Getting data for Table: Genre\n",
      "Checking Azure for existing CSV\n",
      "Existing file found, uploading new version\n",
      "Getting data for Table: Collections\n",
      "Checking Azure for existing CSV\n",
      "Existing file found, uploading new version\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, uuid\n",
    "from dotenv import load_dotenv # To access environment variables from a .env file\n",
    "from pyairtable import Api, Base, metadata  # To access Airtable\n",
    "import pandas as pd # To work with data from Airtable\n",
    "import azure_helpers # Helper functions\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__ #to work with Azure\n",
    "\n",
    "\n",
    "# Get variables from .env file\n",
    "load_dotenv()\n",
    "AIRTABLE_API_KEY = os.environ.get('AIRTABLE_API_KEY')\n",
    "AIRTABLE_BASE_IDS = os.environ.get('AIRTABLE_BASE_IDS').split(\",\")\n",
    "CONNECT_STR = os.environ.get('AZURE_STORAGE_CONNECTION_STRING')\n",
    "ACCOUNT_NAME = os.environ.get('ACCOUNT_NAME')\n",
    "ACCOUNT_KEY = os.environ.get('ACCOUNT_KEY')\n",
    "CONTAINER_NAME = os.environ.get('CONTAINER_NAME')\n",
    "DIRECTORIES = os.environ.get('DIRECTORIES').split(\",\")\n",
    "\n",
    "# Load Azure Client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECT_STR)\n",
    "container_client = container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
    "\n",
    "for base_id in AIRTABLE_BASE_IDS:\n",
    "\n",
    "    # Load Base\n",
    "    api = Api(AIRTABLE_API_KEY)\n",
    "    my_base = Base(AIRTABLE_API_KEY, base_id)\n",
    "    base_name = base_id\n",
    "    schema = metadata.get_base_schema(my_base)\n",
    "    tables = schema['tables']\n",
    "\n",
    "\n",
    "    if not os.path.isdir(\"Bases\"): os.makedirs('Bases')\n",
    "\n",
    "    # Check if Each Folder Directory Exists, if not make one\n",
    "    for dir in DIRECTORIES:\n",
    "        path = f'Bases/{base_name}/{dir}'\n",
    "        folderExists = os.path.isdir(path)\n",
    "\n",
    "        if folderExists:\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(path)\n",
    "\n",
    "    # For each table in a base\n",
    "    for table in tables:\n",
    "\n",
    "        # Get Table Data and create CSV from JSON\n",
    "        table_name = table['name']\n",
    "        filename = f'Bases/{base_name}/Tables/{table_name}.csv'\n",
    "        azure_filename = f'Bases/{base_name}/Tables/{table_name}.csv'      \n",
    "        print(f'Getting data for Table: {table_name}')\n",
    "\n",
    "        # Format Table Data\n",
    "        table_data_raw = my_base.all(table['id'], cell_format=\"string\", user_locale='en-ie', time_zone='America/New_York') # Update Locale and Timezone\n",
    "        table_data = azure_helpers.add_record_ids(table_data_raw)\n",
    "        table_df = pd.DataFrame(table_data)\n",
    "        table_df.columns = table_df.columns.str.replace(' ', '_')\n",
    "        table_df.columns = table_df.columns.str.lower()\n",
    "        table_csv = table_df.to_csv(filename, index=False)\n",
    "\n",
    "        # Check Azure Container for contents and instance of CSV\n",
    "        print('Checking Azure for existing CSV')\n",
    "        check_azure = container_client.list_blobs()\n",
    "        blob_names = [x.name for x in check_azure]\n",
    "        blob_count = len(blob_names)\n",
    "        no_content = blob_count == 0\n",
    "        file_exists = None\n",
    "        blob_client = blob_service_client.get_blob_client(container=CONTAINER_NAME, blob=filename)\n",
    "\n",
    "\n",
    "        # If there aren't any contents in the container skip to next part\n",
    "        if no_content:\n",
    "            file_exists = False\n",
    "        # If there are contents in the container check to see if file exists\n",
    "        else:\n",
    "            local_filename = f'Bases/{base_name}/Staging/'+table['id']+'.csv'\n",
    "            file_exists =  filename in blob_names\n",
    "            \n",
    "\n",
    "        # If File exists, download file, append, and upload to container then remove from staging\n",
    "        if file_exists:\n",
    "            print('Existing file found, uploading new version')\n",
    "            with open(azure_filename, \"wb\") as download_file:\n",
    "                download_file.write(blob_client.download_blob().readall())\n",
    "            existing_df = pd.read_csv(azure_filename)\n",
    "            frames = [existing_df, table_df]\n",
    "            upload_df = pd.concat(frames).drop_duplicates(subset='airtable_id')        \n",
    "            upload_df.to_csv(filename, index=False)\n",
    "            with open(filename, \"rb\") as upload_file:\n",
    "                blob_client.upload_blob(data=upload_file,overwrite=True)\n",
    "            # os.remove(local_filename)\n",
    "        # If no file exists with that table id/name in container uplpad the CSV Upload File\n",
    "        else:\n",
    "            print('No existing file found, uploading a new file to Azure')\n",
    "            with open(filename, \"rb\") as upload_file:\n",
    "                blob_client.upload_blob(data=upload_file,overwrite=True)\n",
    "            \n",
    "    print('\\n\\n\\n')\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fe2923d35005760e9405b1963f8afe577e4a56a11a8d1975e046c1eae03502e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
