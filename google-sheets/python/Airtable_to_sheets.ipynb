{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for Table: Movies\n",
      "Formatting Fact Table\n",
      "Formatting Linked Records for genres_linked field\n",
      "Formatting Linked Records for collection field\n",
      "No sheet found for Movies JOIN, creating new table\n",
      "Successfully uploaded Movies JOIN! \n",
      "\n",
      "Sheet for Movies found. appending table\n",
      "Successfully uploaded Movies! \n",
      "\n",
      "Getting data for Table: Genre\n",
      "Sheet for Genre found. appending table\n",
      "Successfully uploaded Genre! \n",
      "\n",
      "Getting data for Table: Collections\n",
      "Sheet for Collections found. appending table\n",
      "Successfully uploaded Collections! \n",
      "\n",
      "Success! All Tables Uploaded to Google Sheet\n"
     ]
    }
   ],
   "source": [
    "import logging, os\n",
    "from gcs_helpers import add_record_ids, sheets_upload, format_linked_records\n",
    "import pandas as pd # To work with data\n",
    "from pyairtable import Base, metadata # To Access Airtable \n",
    "from dotenv import load_dotenv # To Access Environment Variables\n",
    "\n",
    "# Declare Variables from .env\n",
    "load_dotenv()\n",
    "AIRTABLE_API_KEY = os.environ.get('AIRTABLE_API_KEY')\n",
    "AIRTABLE_BASE_ID = os.environ.get('AIRTABLE_BASE_ID')\n",
    "directories = ['Tables', 'Staging','JSON']\n",
    "\n",
    "# Declare primary fact table\n",
    "fact_tables = ['Movies']\n",
    "\n",
    "# Load Base\n",
    "my_base = Base(AIRTABLE_API_KEY, AIRTABLE_BASE_ID)\n",
    "my_base_metadata = metadata.get_base_schema(my_base)['tables']\n",
    "schema = metadata.get_base_schema(my_base)\n",
    "tables = schema['tables']\n",
    "table_ids = [x['id'] for x in tables]\n",
    "\n",
    "# For each table in a base\n",
    "for table in tables:\n",
    "\n",
    "    # Get Table Data and create json from output\n",
    "    table_name = table['name']\n",
    "\n",
    "    print(f'Getting data for Table: {table_name}')\n",
    "\n",
    "    table_data_raw = my_base.all(table['id'])\n",
    "    table_data = add_record_ids(table_data_raw) #Add airtable record ids to output\n",
    "    table_df = pd.DataFrame(table_data)\n",
    "\n",
    "    # Get Array Fields\n",
    "    table_index = tables.index(table)\n",
    "    table_fields = my_base_metadata[table_index]['fields']\n",
    "    linked_fields = [x for x in table_fields if x['type'] in 'multipleRecordLinks']\n",
    "    array_field_types = ['multipleRecordLinks','multipleCollaborators','multipleSelects','multipleAttachments','mutipleLookupValues']\n",
    "    array_fields = [x['name'] for x in table_fields if x['type'] in array_field_types]\n",
    "    non_array_fields = [x['name'] for x in table_fields if x['type'] not in array_field_types and table_fields.index(x) != 0]\n",
    "\n",
    "    # If table is the primary fact table - explode linked record columns and create a join.json file\n",
    "    if table_name in fact_tables:\n",
    "\n",
    "        print('Formatting Fact Table')\n",
    "        # Format Linked Records\n",
    "        table_df = format_linked_records(linked_fields,table_df,tables,table_ids,my_base)\n",
    "        \n",
    "        # Transform Join Table by exploding fields\n",
    "        join_df = table_df\n",
    "        join_df = join_df.drop(columns=non_array_fields)\n",
    "        for field in array_fields:\n",
    "            join_df[field] = join_df[field].apply(lambda d: d if isinstance(d, list) else [])\n",
    "            join_df = join_df.explode(field)\n",
    "        \n",
    "        # Upload tables to google sheets\n",
    "        join_table_name = f'{table_name} JOIN'\n",
    "        sheets_upload(join_df, join_table_name)\n",
    "        sheets_upload(table_df, table_name)\n",
    "    else:\n",
    "        #Drop Array Fields that are captured in join_df\n",
    "        table_df = table_df.drop(columns=array_fields)\n",
    "        sheets_upload(table_df,table_name)\n",
    "\n",
    "print('Success! All Tables Uploaded to Google Sheet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collection', 'id', 'airtable_id'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_df.columns"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
